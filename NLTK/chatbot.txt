
Definition
Representing Images on Multiple Layers of Abstraction in Deep Learning
Representing Images on Multiple Layers of Abstraction in Deep Learning
Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.

Overview
Most modern deep learning models are based on artificial neural networks, specifically, Convolutional Neural Networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines

In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. 

The word "deep" in "deep learning" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.[14] Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.

Deep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.

For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.

Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors and deep belief networks.

Interpretations
Deep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.

The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as the rectified linear unit.


Applications
Automatic speech recognition
Main article: Speech recognition
Large-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn "Very Deep Learning" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.

The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.

Who did the first work generally recognized as AI?	Warren McCulloch and Walter Pitts (1943).
What sources was drawn on the formation of the first work generally recognized as AI?	knowledge of the basic physiology and function of neurons in the brain; a formal analysis of propositional logic due to Russell and Whitehead; and Turing's theory of computation.
Who created the Hebbian learning rule?	Donald Hebb (1949).
When the first neural network is built?	1950.
What is the first neural network called?	The SNARC.
Who introduced the Turing test, machine learning, genetic algorithms, and reinforcement learning?	Alan Turing.
Alan Turing prefer what method on creating human-level Al?	He prefer to develop learning algorithms and then teach the machine rather than by programming its intelligence by hand.
Who presented the Logic Theorist (LT)?	Allen Newell and Herbert Simon from Carnegie Tech.
What does General Problem Solver (GPS) is designed for?	GPS was designed from the start to imitate human problem-solving protocols.
Which model was robably the first program to embody the “thinking humanly” approach?	General Problem Solver (GPS).
Who formulate the famous physical symbol system hypothesis?	Allen Newell and Herbert Simon.
What does physical symbol system hypothesis states?	a physical symbol system has the necessary and sufficient means for general intelligent action.
Who constructed the Geometry Theorem Prover?	Herbert Gelernter (1959).
Who, on checkers, thereby disproved the idea that computers can do only what they are told to?	Arthur Samuel
Who defined the high-level language Lisp?	John McCarthy.
Whatlanguage, in 1958, has become the dominant Al programming language for the next 30 years?	Lisp
who discovered a complete theorem-proving algorithm for first-order logic in 1965?	J. A. Robinson's
Which program in 1963 was able to solve closed-form calculus integration problems typical of MIT's first-year college courses?	James Slagle's Saint program
What is the most famous microworld?	The blocks world.
What does the perceptron convergence theorem say?	The theorem says that the learning algorithm can adjust the connection strengths of a perceptron to match any input data, provided such a match exists.
What does the book Preceptrons (1969) mentioned?	Although perceptrons (a simple form of neural network) could be shown to learn anything they were capable of representing, they could represent very little. 
What is the weak methods in 1969?	a general-purpose search mechanism trying to string together elementary reasoning steps to find complete solutions.
Why weak methods in 1969 are called weak methods?	They do not scale up to large or difficult problem instances.
Why is the DENDRAL program powerful, according to its authors?	It embodied the relevant knowledge of mass spectroscopy not in the form of first principles but in efficient “cookbook recipes” (Feigenbaum et al., 1971). 
Which program is the first successful knowledge-intensive system?	The DENDRAL program.
What does knowledge-intensive system mean?	A system that its expertise derived from large numbers of special-purpose rules.
What is the content of the Heuristic Programming Project (HPP)?	It is to investigate the extent to which the new methodology of expert systems could be applied to other areas.
What function does MYCIN system contribute in?	diagnosing blood infections.
What is the major differences between MYCIN and DENDRAL?	First, unlike the DENDRAL rules, no general theoretical model existed from which the Mycin rules could be deduced. Second, the rules had to reflect the uncertainty associated with medical knowledge.
What calculus of uncertainty does MYCIN incorporated?	certainty factors.
How is the performance of certainty factors in MYCIN?	It seemed (at the time) to fit well with how doctors assessed the impact of evidence on the diagnosis.
Which system is the first successful commercial expert system?	R1.
Where does the first successful commercial expert system began operation?	The Digital Equipment Corporation (McDermott, 1982).
What does robust language understanding requires?	general knowledge about the world and a general method for using that knowledge.
What does Minsky's idea of frames (1975) implies?	assembling facts about particular object and event types and arranging the types into a large taxonomic hierarchy analogous to a biological taxonomy.
What is the content of the “Fifth Generation” project announced by the Japanese government in 1981?	A 10-year plan to build massively parallel, intelligent computers running Prolog. 
What caused the "AI winter"?	Many companies fell by the wayside as they failed to deliver on extravagant promises.
Why, after 1988, it turned out to be difficult to build and maintain expert systems for complex domains?	In part becausethe reasoning methods used by the systems broke down in the face of uncertainty and in part because the systems could not learn from experience.
Who described symbols as the “luminiferous aether of Al”?	Geoff Hinton
What does “luminiferous aether of Al” by Geoff Hinton mean?	A reference to the non-existent medium through which many 19th-century physicists believed that electromagnetic waves propagated.
How is the connectionist models better suited to the messiness of the real world?	It forms internal concepts in a more fluid and imprecise way.
What approach does the brittleness of expert systems led to?	It is an approach incorporating probability rather than Boolean logic, machine learning rather than hand-coding, and experimental results rather than philosophical claims.
What approach dominate the field of speech recognition?	The approach using hidden Markov models (HMMs).
What are the characteristics of HMMs in the feild of speech recognition?	First, they are based on a rigorous mathematical theory. Second, they are generated by a process of training on a large corpus of real speech data. 
Which year is an important year for the connection between Al and other fields?	1988
In 1998, what fields does AI connected to?	statistics, operations research, decision theory, and control theory.
Whose research led to a new acceptance of probability and decision theory in Al?	Judea Pearl's (1988).
What does Pearl's development of Bayesian networks yielded?	It yielded a rigorous and efficient formalism for representing uncertain knowledge as well as practical algorithms for probabilistic reasoning
What major contribution is done by Rich Sutton in 1988?	connecting reinforcement learning to the theory of Markov decision processes (MDPs) developed in the field of operations research.
What kind of advances facilitated the big data phenomenon?	Remarkable advances in computing power and the creation of the World Wide Web.
Who argued that the improvement in performance obtained from increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be obtained from tweaking the algorithm?	Banko and Brill (2001)
Who developed a clever method for filling in holes in photographs by blending in pixels from similar images?	Hays and Efros (2007).
What does the term deep learning refers to?	It refers to machine learning using multiple layers of simple, adjustable computing elements.
What method do experiments found some success in handwritten digit recognition in the 1990s?	convolutional neural networks.
How does deep network contribute to ALPHAGO's victories over the leading human Go players?	representing the evaluation function.
What is the mean for Ford (2018) interviews of AI experts in the question of when (if ever) will AI systems achieve human-level performance across a broad variety of tasks?	2099
What system does U.S. forces deployed to do automated logistics planning and scheduling for transportation?	 a Dynamic Analysis and Replanning Tool, Dart.
What AI system defeated world chess champion Garry Kasparov in 1997?	Deep Blue
What AI system defeated the world GO champion Ke Jie?	ALPHAGO
What ALPHAZERO can do?	It used no input from humans (except for the rules of the game), and was able to learn through self-play alone to defeat all opponents, human and machine, at Go, chess, and shogi 
What does the deep learning model, which won the 2018 Gordon Bell Prize, do?	It discovers detailed information about extreme weather events that were previously buried in climate data.
Who noted that the “mechanical arts are of ambiguous use, serving as well for hurt as for remedy”?	Francis Bacon
Where does the statement “mechanical arts are of ambiguous use, serving as well for hurt as for remedy” be noted?	The Wisdom of the Ancients (1609)
Who suggested that “First solve Al, then use Al to solve everything else.”?	Demis Hassabis, CEO of Google DeepMind.
How does United Nations define "Lethal Autonomous Weapons"?	weapons that can locate, select, and eliminate human targets without human intervention.
What possible risks we might face on devoloping AI?	Lethal Autonomous Weapons, surveillance and persuasion, biased decision making, impact on employment, safety-critical applications, cybersecurity and so on.
Who reminded that the field of those broader goals and warned that the subfields were in danger of becoming ends in themselves?	Nils Nilsson (1995)
Who was motivated to consider the long-term future of Al after seeing Arthur Samuel's checker-playing program learn to beat its creator?	Norbert Wiener
What does the Kind Midas problem implies?	Midas, a legendary King in Greek mythology, asked that everything he touched should turn to gold, but then regretted it after touching his food, drink, and family members.
What is the definition of agent?	anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.
What the word percept refer to?	It refer to the content an agent's sensors are perceiving.
What is an agent's percept sequence?	the complete history of everything the agent has ever perceived.
In general, what does an agent's choice of action at any given instant depend on?	It can depend on its built-in knowledge and on the entire percept sequence observed to date, but not on anything it hasn't perceived.
What can we say mathematically on an agent's behavior?	An agent's behavior is described by the agent function that maps any given percept sequence to an action.
How AI is stucked to consequentialism?	We evaluate an agent's behavior by its consequences.
How can we capture the desirability related to consequentialism of an AI model?	It can be captured by a performance measure that evaluates any given sequence of environment states.
What is the difference on desirability between human and machine?	Human measures it from their point of view, while machine do not have desires and preferences of their own.
Who warns to ensure that “the purpose put into the machine is the purpose which we really desire”?	Norbert Wiener.
How, better, should we design performance measurers for AI?	according to what one actually wants to be achieved in the environment.
What does the King Midas problem inspire us?	We must accept the possibility that we might put the wrong purpose into the machine.
What can the definition of rational depends on?	The performance measure that defines the criterion of success; The agent's prior knowledge of the environment; The actions that the agent can perform; The agent’s percept sequence to date.
What is the difference of omniscience from rationality?	An omniscient agent knows the actual outcome of its actions and can act accordingly; but omniscience is impossible in reality.
What is the relationship between rationality and perfection?	Rationality maximizes expected performance, while perfection maximizes actual performance.
What information gathering means?	Doing actions in order to modify future percepts.
How we will say that an agent lacks autonomy?	An agent relies on the prior knowledge of its designer rather than on its own percepts and learning processes.
What does an autonomous rational agent do?	It should learn what it can to compensate for partial or incorrect prior knowledge.
What is task environments?	They are essentially the “problems” to which rational agents are the “solutions.”
What is PEAS description?	Specify the performance measure, the environment, and the agent's actuators and sensors under the heading of the task environment.
What we can do as the range of task environments that might arise in Al is obviously vast?	We can identify a fairly small number of dimensions along which task environments can be categorized.
What dimensions we can indentify on task environments?	Fully observable vs. partially observable; single-agent vs. multiagent; deterministic vs. nondeterministic; episodic vs. sequential; static vs. dynamic; discrete vs. continuous; known vs. unknown
How can we say a task environment is fully observable?	an agent's sensors give it access to the complete state of the environment at each point in time.
How can we say a task environment is deterministic?	The next state of the environment is completely determined by the current state and the action executed by the agent(s).
What task environment makes an agent need not worry about uncertainty?	fully observable and deterministic.
What is the difference between stochastic and nondeterministic?	We say that a model of the environment is stochastic if it explicitly deals with probabilities (e.g., “there's a 25% chance of rain tomorrow”) and “nondeterministic” if the possibilities are listed without being quantified (e.g., “there's a chance of rain tomorrow”).
How can we say a task environment is episodic?	The agent's experience is divided into atomic episodes, which in each episode the agent receives a percept and then performs a single action. Crucially, the next episode does not depend on the actions taken in previous episodes.
How can we say a task environment is sequential?	The current decision of agent could affect all future decisions.
What are the examples of episodic and sequential task environments?	Many classification tasks are episodic; Chess and taxi driving are sequential.
Why episodic environments are much simpler than sequential environments?	The agent does not need to think ahead.
How can we say a task environment is dynamic for that agent?	The environment can change while an agent is deliberating.
How can we say a task environment is static for that agent?	The environment cannot change while an agent is deliberating.
Why static task envrionments are easy to deal with?	The agent need not keep looking at the world while it is deciding on an action, nor need it worry about the passage of time.
How can we say a task environment is semidynamic?	The environment itself does not change with the passage of time but the agent's performance score does.
What are the examples of dynamic, semidynamic and static task environments?	Taxi driving is clearly dynamic; Chess, when played with a clock, is semidynamic; Crossword puzzles are static.
What are the differences between discrete and continuous task environments?	The state of the environment, to the way time is handled, and to the percepts and actions of the agent.
What are the examples of discrete and continuous task environments?	Chess has a finite number of distinct states (excluding the clock), and a discrete set of percepts and actions; Taxi driving is a continuous-state and continuous-time problem.
What does a known / unknown task environment refers to?	 The agent's (or designer's) state of knowledge about the “laws of physics” of the environment.
How can we say a task environment is known?	The outcomes (or outcome probabilities if the environment is nondeterministic) for all actions are given.
How can we say a task environment is unknown?	The agent will have to learn how it works in order to make good decisions.
What is an example of partially observable and known task environment?	In solitaire card games, I know the rules but am still unable to see the cards that have not yet been turned over.
What is an example of fully observable and unknown task environment?	In a new video game, the screen may show the entire game state but I still don't know what the buttons do until I try them.
What kind of task environment should be the hardest case?	partially observable, multiagent, nondeterministic, sequential, dynamic, continuous, and unknown.
What is an agent function?	The mapping from percepts to actions.
What is the agent architecture?	A program will run on some sort of computing device with physical sensors and actuators
What the architecture does to a program?	In general, the architecture makes the percepts from the sensors available to the program, runs the program, and feeds the program's action choices to the actuators as they are generated.
What are the four basic kinds of agent programs that embody the principles underlying almost all intelligent systems?	Simple reflex agents; Model-based reflex agents; Goal-based agents; and Utility-based agents.
What does simple reflex agents do?	These agents select actions on the basis of the current percept, ignoring the rest of the percept history.
What does condition-action rule similar to?	if-then statements.
What is the more general and flexible approach for simple reflex agent?	Firstly build a general-purpose interpreter for condition-action rules and then to create rule sets for specific task environments.
How can a simple reflex agen escape from infinite loops?	The agent can randomize its actions.
What is better instead of allowing simple reflex agents to randomize its actions?	A more sophisticated deterministic agent.
What is the most effective way to handle partial observability for the agent?	The agent should maintain some sort of internal state that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. 
What kind of knowledge is required in updating model-based reflex agents' internal state information as time goes by?	First, we need some information about how the world changes over time. Second, we need some information about how the state of the world is reflected in the agent's percepts.
How the information about how the world changes over time in model-based reflex agent can be divided?	The effects of the agent's actions and how the world evolves independently of the agent.
What does the knowledge about “how the world works” is called?	The transition model of the world.
What is sensor model in model-based reflex agent?	A kind of knowledge, which is some information about how the state of the world is reflected in the agent's percepts.
What is the definition of model-based reflex agent?	An agent using transition model and sensor model.
How transition model and sensor model function in model-based reflex agent?	allow an agent to keep track of the state of the world.
Which part in model-based reflex agent's structure is interesting?	The function which is responsible for creating the new internal state description.
What does the model-based reflex agent's knowing of the current world actually is?	It represents the agent's “best guess”, as regardless of the kind of representation used, it is seldom possible for the agent to determine the current state of a partially observable environment exactly.
What does goal information do to agents?	It describes situations that are desirable.
How a goal-based agent appears being more flexible?	It may appears less efficient.
Why economists and computer scientists use the term utility instead?	It is because it sounds more scientific then words like "happy".
What will happen if the internal utility function and the external performance measure are in agreement?	An agent that chooses actions to maximize its utility will be rational according to the external performance measure.
What does a utility function do when there are conflicting goals?	It specifies the appropriate tradeoff.
What does a utility function do when there are several goals that the agent can aim for?	It provides a way in which the likelihood of success can be weighed against the importance of the goals.
How can we say technically about a rational utility-based agent?	It chooses the action that maximizes the expected utility of the action outcomes—that is, the utility the agent expects to derive, on average, given the probabilities and utilities of each outcome. 
What will happen if an agent possesses an explicit utility function?	It can make rational decisions with a general-purpose algorithm that does not depend on the specific utility function being maximized.
What is hard in utility-based function?	A utility-based agent has to model and keep track of its environment; Choosing the utility-maximizing course of action.
What is the advantage for agent to learn?	It allows the agent to operate in initially unknown environments and to become more competent than its initial knowledge alone might allow.
What is the conceptual components for a learning agent?	Learning element; Performance element; Critic; Problem Generator.
What does the learning element in the components for a learning agent do?	It is responsible for making improvements.
What does the performance element in the components for a learning agent do?	It is responsible for selecting external actions.
What does the critic in the components for a learning agent do?	The critic tells the learning element how well the agent is doing with respect to a fixed performance standard.
How should we think when we are trying to design an agent that learns a certain capability?	The first question is not “How am I going to get it to learn this?” but “What kind of performance element will my agent use to do this once it has learned how?” 
Why critic is necessary for a learning agent?	The percepts themselves provide no indication of the agent's success. 
What does the problem generator in the components for a learning agent do?	It is responsible for suggesting actions that will lead to new and informative experiences.
What will happen if an agent is willing to explore a little and do some perhaps suboptimal actions in the short run?	It might discover much better actions for the long run.
What is needed when we are trying to learn a reflex component or a utility function?	Information from the external standard.
What does the performance standard distinguishes part of the incoming percept as?	A reward or penalty that provides direct feedback on the quality of the agent's behavior.
How can we rank the representations of task environments in their expressiveness?	Atomic, factored and structured.
What does a particular agent component that deals with “What my actions do” do?	It describes the changes that might occur in the environment as the result of taking an action, and Figure 2.16!2 provides schematic depictions of how those transitions might be represented.
What happens in an atomic representation?	Each state of the world is indivisible—it has no internal structure.
What are the examples of areas work with atomic representations?	Search and game-playing, hidden Markov models and Markov decision processes.
What does a factored representation do?	It splits up each state into a fixed set of variables or attributes, each of which can have a value.
What are the examples of areas work with factored representations?	Constraint satisfaction algorithms, propositional logic, planning, Bayesian networks and various machine learning algorithms.
What happens in a structured representation?	Objects and their various and varying relationships can be described explicitly
When we need the structured representation?	When we need to understand the world as having things in it that are related to each other, not just variables with values.
What are the examples of areas work with structured representations?	Relational databases and first-order logic, first-order probability models, and much of natural language understanding.
How reasoning and learning changes following to the expressive power of the representation of an agent's environment?	Reasoning and learning become more complex as the expressive power of the representation increases.
How can we gain the benefits of expressive representations of agent environments while avoiding their drawbacks?	Intelligent systems for the real world may need to operate at all points along the axis simultaneously
What happens in a localist representation?	There is a one-to-one mapping between concepts and memory locations.
What happens in a distributed representation?	The representation of a concept is spread over many memory locations, and each memory location is employed as part of the representation of multiple different concepts.
Which representations are more robust against noise and information loss, localist one or distributed one?	Distributed representations.
What bad situation might happen using localist representations?	The mapping from concept to memory location is arbitrary, and if a transmission error garbles a few bits, we might confuse Truck with the unrelated concept Truce.
What is the definition of problem-solving agent?	An agent that need to plan ahead: to consider a sequence of actions that form a path to a goal state.
What is the definition of search?	The computational process that a problem-solving agent undertakes.
What representations do Problem-solving agents use?	Atomic representations.
What happens to informed algorithms?	The agent can estimate how far it is from the goal.
What happens to uninformed algorithms?	The agent cannot estimate how far it is from the goal.
What is the four-phrase problem-solving process?	Goal formulation; problem formulation; Search; Execution.
What an agent does in goal formulation phase?	The agent adopts the goal of a task.
How does the goals act in an agent's goal formulation phase?	Goals organize behavior by limiting the objectives and hence the actions to be considered.
What an agent does in problem formulation phase?	The agent devises a description of the states and actions necessary to reach the goal—an abstract model of the relevant part of the world.
What an agent does in search phase?	Before taking any action in the real world, the agent simulates sequences of actions in its model, searching until it finds a sequence of actions that reaches the goal. 
What is the definition of solution for problem-solving agent?	A sequence of actions that reaches the goal.
What an agent does in execution phase?	The agent excute the actions in the solution, one at a time.
How is the solution in a fully observable, deterministic, known environment?	The solution to any problem is a fixed sequence of actions.
What open-loop system is by the control theorists?	A system ignoring the percepts breaks the loop between agent and environment.
Which loop is more safer for a problem-solving agent, open-loop or closed-loop?	Closed-loop approach.
How is the solution in a partially observable or nondeterministic environment?	A solution would be a branching strategy that recommends different future actions depending on what percepts arrive.
What is the definition of the state space?	A set of possible states that the environment can be in.
What is the definition of the initial state?	The state that the agent starts in.
What is the definition of the goal states?	A set of states that are goals to the agent.
What is the definition of transition model to problem-solving agent?	A model which describes what each action does.
What is the definition of action cost function?	A function reflects an agent's own performance measure.
What is the definition of a search "problem"?	The combination of a state space, an initial state, one or more goal states, transition models and action cost functions.
What is the definition of an optimal solution?	The solution having the lowest path cost.
What is the possible meaning of model?	An abstract mathematical description, which is not the real thing.
What is the definition of abstraction?	The process of removing detail from a representation.
How can we say an abstraction is good?	It involves removing as much detail as possible while retaining validity and ensuring that the abstract actions are easy to carry out.
What will happen if we don't have the ability to construct useful abstractions?	The intelligent agents would be completely swamped by the real world.
What is the definition of standardized problem?	It is intended to illustrate or exercise various problem-solving methods.
How can researchers use a standardized problem?	A standardized problem is suitable as a benchmark for researchers to compare the performance of algorithms.
What is the definition of real-world problem?	It is one whose solutions people actually use, and whose formulation is idiosyncratic, not standardized.
What is a grid world problem?	It is a two-dimensional rectangular array of square cells in which agents can move from cell to cell.
What agents can do to objects in cells in a grid world problem?	Cells can contain objects, which the agent can pick up, push, or otherwise act upon.
What wall or impassible obstacles do in a grid world problem?	Those things in a cell prevents an agent from moving into that cell.
What is the example of a grid world problem?	Sokoban puzzle.
What is a sokoban puzzle?	It is a puzzle that the agent's goal is to push a number of boxes, scattered about the grid, to designated storage locations. 
What is a sliding-tile puzzle?	It is a puzzle that a number of tiles (sometimes called blocks or pieces) are arranged in a grid with one or more blank spaces so that some of the tiles can slide into the blank space.
What is a touring problem?	It is a problem that describes a set of locations that must be visited, rather than a single goal destination.
What is the traveling salesperson problem (TSP)?	It is a touring problem in which every city on a map must be visited.
What does a VLSI layout problem requires?	It requires positioning millions of components and connections on a chip.
What does a VLSI layout problem aims to?	It aims to minimize area, minimize circuit delays, minimize stray capacitances, and maximize manufacturing yield.
How does the VLSI layout problem be splited?	It is split into two parts: cell layout and channel routing.
What is the difference of robot navigation from following distinct paths?	A robot can roam around, in effect making its own paths.
What problem do real robots must also deal with in robot navigation?	Their sensor readings and motor controls, with partial observability, and with other agents that might alter the environment.
Since when does the automatic assembly sequencing of complex objects (such as electric motors) by a robot have been standard industry practice?	1970s.
What is protein design?	It is an assembly problem, in which the goal is to find a sequence of amino acids that will fold into a three-dimensional protein with the right properties to cure some disease.
What is the definition of search algorithm?	A search algorithm takes a search problem as input and returns a solution, or an indication of failure.
What does a node in a search tree corresponds to?	A state in the state space.
What does an edge in a search tree corresponds to?	An action.
What does the root in a search tree corresponds to?	The initial state of the problem.
What is the distinction of the state space from the search tree?	The state space describes the (possibly infinite) set of states in the world, and the actions that allow transitions from one state to another. 
What is the distinction of the search tree from the state space?	The search tree describes paths between these states, reaching towards the goal. The search tree may have multiple paths to (and thus multiple nodes for) any given state, but each node in the tree has a unique path back to the root (as in all trees).
What is the process of expanding a node?	We can expand the node, by considering the available actions for that state, see where those actions lead to, and generating a new node (called a child node or successor node) for each of the resulting states.
If A is a child node of B, what B is of A?	Parent node.
What is the essence of search?	Following up one option now and putting the others aside for later.
How can we say a node is reached?	The node has had a node generated for it.
What is best-first search?	We choose a node, n, with minimum value of some evaluation function, f(n).
What is node?	A node in the tree is represented by a data structure with four components: State; Parent; Action; Path cost.
What is the componenets of a node?	State; Parent; Action; Path cost.
What is queue?	A data structure used to store the frontier.
What are the possible operations on a frontier?	check whether it is empty; remove the top node; return the top node; insert node into proper place
What is a priority queue?	A kind of queue which first pops the node with the minimum cost according to some evaluation function, f.
Where does a priority queue might be used?	It is used in best-first search.
What is a first-in-first-out (FIFO) queue?	A kind of queue which  first pops the node that was added to the queue first.
Where does a FIFO queue might be used?	It is used in breadth-first search.
What is a last-in-first-out (LIFO) queue?	A kind of queue which  first pops the node that was added most recently to the queue.
Where does a LIFO queue might be used?	It is used in depth-first search.
What is the example of loopy path in a search?	The search goes repeatedly between two states.
what is the possible consequence if loopy path occurs in a search?	The complete search tree is infinite.
What should be eliminated in the search?	Redundant paths.
What possible methods can be used to eliminate redundant paths?	Remember all previously reached states to detect redundant paths; do not consider it for minor problem formulations; only check for cycles but not for redundant paths in general.
What is a graph search?	A search algorithm which checks for redundant paths.
What is a tree-like search?	A search algorithm which does not check for redundant paths.
What is an example of graph search algorithm?	The Brst-First-Search algorithm.
What are the evaluation methods on an algorithm’s performance?	Completeness; Cost optimality; Time complexity; Space complexity.
What does Completeness evaluates specificly on an algorithm's performance?	Is the algorithm guaranteed to find a solution when there is one, and to correctly report failure when there is not?
What does Cost optimality evaluates specificly on an algorithm's performance?	Does it find a solution with the lowest path cost of all solutions?
What does Time complexity evaluates specificly on an algorithm's performance?	How long does it take to find a solution? This can be measured in seconds, or more abstractly by the number of states and actions considered.
What does Space complexity evaluates specificly on an algorithm's performance?	How much memory is needed to perform the search?
What kind of search algorithm will be complete?	A search algorithm which is systematic in the way it explores an infinite state space, making sure it can eventually reach any state that is connected to the initial state.
What evaluation methods on an algorithm’s performance are considered with respect to some measure of the problem difficulty?	Time and space complexity.
What variables can we use in measuring the complexity of an algorithm?	d, the depth; m, the maximum number of actions in any path; b, the branching factor
What is an informed search strategy?	One that uses domain-specific hints about the location of goals.
What is heuristic function?	The estimated cost of the cheapest path from the state at node n to a goal state.
What is Greedy best-first search?	Greedy best -first search is a form of best-first search that expands first the node with the lowest value on the grounds that this is likely to lead to a solution quickly.
Why the algorithm is called “greedy”?	On each iteration it tries to get as close to a goal as it can, but greediness can lead to worse results than being careful.
What is A* search?	A* search is a best-first search that uses the evaluation function f(n) = g(n) + h(n).
What is g(n)?	g(n) is the path cost from the initial state to node n.
What is f(n)?	f(n) is the estimated cost of the best path that continues from n to a goal.
What is the properties of A* search?	A* search is complete, cost-optimal, and optimally efficient.
What is the drawback of A* search?	A* search uses a lot of space and memory.
What is an admissible heuristic?	An admissible heuristic is one that never overestimates the cost to reach a goal. 
What is a contour?	A contour is a useful way to visualize a search by drawing it in the state space.
Does uniform-cost search has contours?	Yes, but it is of g-cost, not g+h.
What does the contours with uniform-cost search look like?	The contours with uniform-cost search will be “circular” around the start state, spreading out equally in all directions with no preference towards the goal. 
What is satisficing solutions?	Satisficing solutions are when we accept solutions that are suboptimal, but are “good enough”.
What is bounded suboptimal search?	We look for a solution that is guaranteed to be within a constant factor W of the optimal cost.
Which algorith provides bounded suboptimal search?	Weighted A* provides bounded suboptimal search.
What is bounded-cost search?	We look for a solution whose cost is less than some constant C.
What is unbounded-cost search?	We accept a solution of any cost, as long as we can find it quickly.
What is the example of an unbounded-cost search algorithm?	An example of an unbounded-cost search algorithm is speedy search.
What is speedy search?	The speedy search is a version of greedy best-first search that uses as a heuristic the estimated number of actions required to reach a goal, regardless of the cost of those actions.
What is Iterative-deepening A* search?	Iterative-deepening A* search (IDA*) is to A* what iterative-deepening search is to depthfirst.
What is the benefits of Iterative-deepening A* search?	Iterative-deepening A* search gives us the benefits of A* without the requirement to keep all reached states in memory, at a cost of visiting some states multiple times.
What is recursive best-first search?	Recursive best-first search attempts to mimic the operation of standard best-first search, but using only linear space.
What is beam search?	Beam search puts a limit on the size of the frontier; that makes it incomplete and suboptimal, but it often finds reasonably good solutions and runs faster than complete searches.
How to construct good heuristics?	 One can sometimes construct good heuristics by relaxing the problem definition, by storing precomputed solution costs for subproblems in a pattern database, by defining landmarks, or by learning from experience with the problem class.
How do local search algoritms function?	Local search algorithms operate by searching from a start state to neighboring states, without keeping track of the paths, nor the set of states that have been reached. 
Are local search algoritms systematic?	No, they might never explore a portion of the search space where a solution actually resides.
What are the advantages of local search algorithms?	They use very little memory; and they can often find reasonable solutions in large or infinite state spaces for which systematic algorithms are unsuitable.
What is hill-climbing search algorithm?	The hill-climbing search algorithm keeps track of one current state and on each iteration moves to the neighboring state with highest value.
Why hill climbing is called greedy local search?	Hill climbing is called greedy local search because it grabs a good neighbor state without thinking ahead about where to go next.
What is the drawback of hill climbing?	Hill climbing can get stuck when it reaches local maxima, ridges and plateaus.
What is a local maximum?	A local maximum is a peak that is higher than each of its neighboring states but lower than the global maximum.
What is a plateau?	A plateau is a flat area of the state-space landscape.
What are the examples of plauteau?	A plauteau is a flat local maximum, from which no uphill exit exists, or a shoulder, from which progress is possible.
What is stochastic hill climbing?	Stochastic hill climbing  chooses at random from among the uphill moves; the probability of selection can vary with the steepness of the uphill move. 
What is first-choice hill climbing?	A first-choice hill climbing implements stochastic hill climbing by generating successors randomly until one is generated that is better than the current state.
What is random-restart hill climbing?	A random-restart hill climbing conducts a series of hill-climbing searches from randomly generated initial states, until a goal is found.
How to get a success hill climbing?	A success hill climbing depends very much on the shape of the state-space landscape: if there are few local maxima and plateaus, random-restart hill climbing will find a good solution very quickly. 
What is simulated annealing?	A simulated annealing combines hill climbing with a random walk in a way that yields both efficiency and completeness.
What is annealing?	Annealing is the process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them, thus allowing the material to reach a low-energy crystalline state.
What is local beam search?	The local beam search algorithm keeps track of k states rather than just one. 
How does the local beam search operate?	It begins with k randomly generated states. At each step, all the successors of all k states are generated. If any one is a goal, the algorithm halts. Otherwise, it selects the k best successors from the complete list and repeats.
What is evolutionary algoritms?	Evolutionary algorithms can be seen as variants of stochastic beam search that are explicitly motivated by the metaphor of natural selection in biology.
What is genetic algorithm?	Genetic algorithms are similar to stochastic beam search, but with the addition of the crossover operation.
When is the genetic algorithm advantageous?	Genetic algorithm is advantageous when there are blocks that perform useful functions.
What are empirical gradient methods?	Empirical gradient methods are methods that measure progress by the change in the value of the objective function between two nearby points
What is a belief state?	 A belief state is a set of physical states that the agent believes are possible.
What is a sensorless problem?	A sensorless problem is when the agent’s percepts provide no information at all.
What are offline search algorithms?	Offline search algorithms compute a complete solution before taking their first action.
What are online search algorithms?	Online search algorithms take an action first, then observe the environment and compute the next action. 
How is an online search problem solved?	An online search problem is solved by interleaving computation, sensing, and acting. 
What is competitive ratio?	Competitive ratio is the comparison of the cost with the path cost the agent would incur if it knew the search space in advance.
What are dead ends?	Dead ends are states from which no goal state is reachable.
What is the meaning of safely explorable?	Safely explorable is when some goal state is reachable from every reachable state. 
What is random walk?	A random walk simply selects at random one of the available actions from the current state
What are competitive environments?	Competitive environments are in which two or more agents have conflicting goals. 
What is an economy?	An economy is to consider a very large number of agents in the aggregate.
What are the examples of games that include an element of chance?	The examples are rolling dice or shuffling cards.
What are the examples of games of imperfect information?	The examples are poker and bridge, where not all cards are visible to all players.
What is "perfect information"?	Perfect information is when the game is fully observable.
What is "zero-sum"?	“Zero-sum” means that what is good for one player is just as bad for the other: there is no “win-win” outcome.
What are the formally defined elements of a game?	A game can be formally defined with initial state, turn to ove, action, a utility function, , a terminal test and transition model.
What is a terminal test?	A terminal test is true when the game is over and false if otherwise.
What is terminal states?	Terminal states are states where the game has ended.
What is a utility function?	A utility function defines the final numeric value to player p when the game ends in terminal state s.
What are the other names of a utility function?	The other names of a utility function are an objective function or payoff function.
What is a state space graph?	A state space graph is a graph where the vertices are states, the edges are moves and a state might be reached by multiple paths.
When do we use minimax search?	We uses minimax search for games with multiple outcome scores.
What is ply?	Ply is used to unambiguously mean one move by one player, bringing us one level deeper in the game tree.
What is the minimax search algorithm?	The minimax search algorithm finds the best move for MAX by trying all actions and choosing the one whose resulting state has the highest MINIMAX value.
Is the minimax search algorithm recursive?	Yes, it is a recursive algorithm that proceeds all the way down to the leaves of the tree and then backs up the minimax values through the tree as the recursion unwinds. 
What is the time complexity for the minimax search algorithm?	The time complexity of the minimax algorithm is O(b^m) if the maximum depth of the tree is m and there are b legal moves at each point.
What is alpha–beta pruning?	The alpha–beta pruning is the particular technique when we compute the correct minimax decision without examining every state by pruning large parts of the tree that make no difference to the outcome.
What is Type A strategy?	A Type A strategy considers all possible moves to a certain depth in the search tree, and then uses a heuristic evaluation function to estimate the utility of states at that depth. 
What is Type B strategy?	A Type B strategy ignores moves that look bad, and follows promising lines “as far as possible.”
What is the difference between the Type A strategy and Type B strategy?	Type A strategy explores a wide but shallow portion of the tree, whereas Type B strategy explores a deep but narrow portion of the tree.
What is the example of games with Type A strategy?	Most of the chess programs have been Type A strategy.
What is the example of games with Type B strategy	Most of the Go programs are more often Type B strategy.
What is forward pruning?	A forward pruning prunes moves that appear to be poor moves, but might possibly be good ones. 
Why we use Monte Carlo tree search?	We use Monte Carlo tree search because  alpha–beta search would be limited to only 4 or 5 ply and , it is difficult to define a good evaluation function for Go.
What are sto4chastic games?	Stochastic games bring us a little closer to the unpredictability of real life by including a random element, such as the throwing of dice.
What is the example of stochastic games?	Backgammon is a typical stochastic game that combines luck and skill. 
What are partially obsercable games?	Partially observable games  includes the use of scouts and spies to gather information and the use of concealment and bluff to confuse the enemy.
What are the examples of partially obsercable games?	Video games such as StarCraft is the example of partially obsercable game.
What are stochastic partial observable games?	Stochastic partial observable games are where the missing information is generated by the random dealing of cards.
What are the examples of stochastic partial observable games?	Card games such as bridge, whist, hearts, and poker feature stochastic partial observability.
When is Monte Carlo search preferred?	When the branching factor is high or it is difficult to define an evaluation function, Monte Carlo search is preferred.
What is the limitation of alpha–beta search?	The limitation of alpha–beta search is its vulnerability to errors in the heuristic function.
What is the limitation of Monte Carlo search?	The limitation of Monte Carlo is that it is designed to calculate the values of legal moves. 
What is metareasoning?	Metareasoning is the kind of reasoning about what computations to do.
What is a constraint satisfaction problem?	A constraint satisfaction problem is A problem that is solved when each variable has a value that satisfies all the constraints on the variable.
What are the components of a constraint satisfaction problem?	The three components are a set of variables (X), a set of domains (D), and  a set of constraints that specify allowable combinations of values (C).
What is a consistent or legal assignment?	A consistent or legal assignment is an assignment that does not violate any constraints.
What is a complete assignment?	A complete assignment is one in which every variable is assigned a value.
What is a solution to a CSP?	A solution to a CSP is a consistent, complete assignment.
What is a partial assignment?	A partial assignment is one that leaves some variables unassigned.
What is a partial solution?	A partial solution is a partial assignment that is consistent.
Why do we formulate a problem as a CSP?	One reason is that the CSPs yield a natural representation for a wide variety of problems; it is often easy to formulate a problem as a CSP.
What are linear constraints?	Linear constraints are  constraints in which each variable appears only in linear form. 
What is unary constraint?	A unary constraint restricts the value of a single variable. 
What is a global constraint?	A global constraint is a constraint involving an arbitrary number of variables.
What is constraint propagation?	It is using the constraints to reduce the number of legal values for a variable, which in turn can reduce the legal values for another variable, and so on. 
What is node-consistency?	A single variable is node-consistent if all the values in the variable’s domain satisfy the variable’s unary constraints. 
What is arc-consistent?	A variable in a CSP is arc-consistent if every value in its domain satisfies the variable’s binary constraints. 
What is the example of algorithm that enforce arc consistency?	The most popular algorithm for enforcing arc consistency is called AC-3. 
What can path consistency do?	Path consistency tightens the binary constraints by using implicit constraints that are inferred by looking at triples of variables.
What is minimum-remaining-values?	Minimum-remaining-value is the idea of choosing the variable with the fewest “legal” values.
What can degree heuristic do?	Degree heuristic attempts to reduce the branching factor on future choices by selecting the variable that is involved in the largest number of constraints on other unassigned variables.
What can the least-constraining-value heuristic do?	The least-constraining-value heuristic prefers the value that rules out the fewest choices for the neighboring variables in the constraint graph.
What is the policy of backtracking-search algorithm?	The backtracking-search algorithm backs up to the preceding variable and try a different value for it. 
What is a backjumping method?	A backjumping method backtracks to the most recent assignment in the conflict set.
What happens to the algorithm when no legal value is found?	When no legal value is found, the algorithm should return the most recent element of the conflict set along with the failure indicator.
What is constraint learning?	Constraint learning is the idea of finding a minimum set of variables from the conflict set that causes the problem.
How can independence be ascertained?	Independence can be ascertained simply by finding connected components of the constraint graph. 
What is a topological sort?	A topological sort is the ordering of picking any variable to be the root of the tree first, and choose an ordering of the variables such that each variable appears after its parent in the tree.
What is a tree decomposition?	A tree decomposition is a transformation of the original graph into a tree where each node in the tree consists of a set of variable.
What is the example of the requirements of a tree decomp7osition?	One of the examples is every variable in the original problem appears in at least one of the tree nodes.
What is an axiom?	An axiom is the sentencet that is taken as being given without being derived from other sentences.
What is an inference?	An inference is deriving new sentences from old.
What requirement should inference obey?	 Inference must obey the requirement that when one asks a question of the knowledge base, the answer should follow from what has been told to the knowledge base previously.
What is the wumpus world?	The wumpus world is a cave consisting of rooms connected by passageways.
What is semantics?	Semantics are the meaning of sentences, which defines the truth of each sentence with respect to each possible world.
What is grounding?	Grounding is the connection between logical reasoning processes and the real environment in which the agent exists.
What is theorem prooving?	Theorem prooving is applying rules of inference directly to the sentences in our knowledge base to construct a proof of the desired sentence without consulting models. 
When is a sentence valid?	A sentence is valid if it is true in all models. 
When is a sentence satisfiable?	A sentence is satisfiable if it is true in, or satisfied by, some model.
What is monotonicity?	A monotonicity says that the set of entailed sentences can only increase as information is added to the knowledge base.
What do the algorithm do in early termination?	The algorithm detects whether the sentence must be true or false, even with a partially completed model.
What is a pure symbol?	A pure symbol is a symbol that always appears with the ame “sign” in all clauses. 
What is a unit clause?	A unit clause was a clause with just one literal. 
What is unit propagation?	Unit propagation resembles the process of forward chaining with definite clauses, and indeed, if the CNF expression contains only definite clauses then DPLL essentially replicates forward chaining. 
What are atemporal variables?	Atemporal variables are symbols associated with permanent aspects of the world that do not need a time superscript.
What is the representational frame problem?	The representational frame problem is the specific manifestation of the frame problem.
How is knowledge contained?	Knowledge is contained in agents in the form of sentences in a knowledge representation language that are stored in a knowledge base.
Why do intelligent agents need knowledge?	Intelligent agents need knowledge about the world in order to reach good decisions.
How is a representation language defined?	A representation language is defined by its syntax, which specifies the structure of sentences, and its semantics, which defines the truth of each sentence in each possible world or model.
Why is the relationship of entailment between sentences is crucial?	The relationship of entailment between sentences is crucial to our understanding ofreasoning.
What is sound inference?	Sound inference algorithms derive only sentences that are entailed.
What are complete algorithms?	 Complete algorithms derive all sentences that are entailed.
What is propositional logic?	Propositional logic is a simple language consisting of proposition symbols and logical connectives.
What can propositional logic do?	Propositional logic can handle propositions that are known to be true, known to be false, or completely unknown.
What are inference rules?	Inference rules are patterns of sound inference that can be used to find proofs. 
What is the resolution rule?	The resolution rule yields a complete inference algorithm for knowledge bases that are expressed in conjunctive normal form.
What are the natural reasoning algorithms for knowledge bases in Horn form?	 Forward chaining and backward chaining are very natural reasoning algorithms for knowledge bases in Horn form.
What is a logical state estimation?	Logical state estimation involves maintaining a logical sentence that describes the set of possible states consistent with the observation history. 
What do each update step of logical state estimation require?	Each update step requires inference using the transition model of the environment, which is built from successorstate axioms that specify how each fluent changes.
How decisions within a logical agent can be made by SAT solving?	It works by finding possible models specifying future action sequences that reach the goal.  
Why does propositional logic do not scale to environments of unbounded size?	This is because e it lacks the expressive power to deal concisely with time, space, and universal patterns of relationships among objects.
How should knowledge representation languages be?	Knowledge representation languages should be declarative, compositional, expressive, context independent, and unambiguous.
How does logic differs?	Logics differ in their ontological commitments and epistemological commitments.
What is the difference in propositional logic and first-order logic?	While propositional logic commits only to the existence of facts, first-order logic commits to the existence of objects and relations and thereby gains expressive power, appropriate for domains such as the wumpus world and electronic circuits.
What is the similarity of propositional logic and first-order logic?	Both propositional logic and first-order logic share a difficulty in representing vague propositions. 
How does the difficulty in representing vague  propositions affect both  propositional logic and first-order logic?	The difficulty limits their applicability in domains that require personal judgments, like politics or cuisine.
What does the syntax of first-order logic does?	It adds terms to represent objects, and has universal and existential quantifiers to construct assertions about all or some of the possible values of the quantified variables.
What does a possible world, or model, for first-order logic include?	A possible world, or model, for first-order logic includes a set of objects and an interpretation that maps constant symbols to objects, predicate symbols to relations among objects, and function symbols to functions on objects.
When is an atomic sentence true?	An atomic sentence is true only when the relation named by the predicate holds between the objects named by the terms. 
What can extended interpretations do?	Extended interpretations, which map quantifier variables to objects in the model, define the truth of quantified sentences.
What is the process of developing a knowledge base in first-order logic?	Developing a knowledge base in first-order logic requires a careful process of analyzing the domain, choosing a vocabulary, and encoding the axioms required to support the desired inferences.
What is AI?	Artificial Intelligence (AI) is the part of computer science concerned with designing intelligent computer systems.
What do the branches of AI have?	NLP, Expert System, Robotics, ANN, Fuzzy Logics, Machine learing and so on.
What is the Turing Test?	Alan Turing devised a test for intelligence called the Imitation Game in.
Under what conditions can intelligence be proved to have passed the test?	If, after multiple tests, the intelligence made an average of more than  per cent of errors per participant, it passed the test and was deemed to have human intelligence.
What capabilities would the AI need?	Natural language processing, Knowledge representation, automated reasoning, machine learning.
What are the cental goals of AI research?	Reasoning, Knowledge representation, Planning, Learning, Natural language processing, Moving and manipulating objects.
What is reasoning?	The reasoning is the mental process of deriving logical conclusion and making predictions from available knowledge, facts, and beliefs.nr
What types of reasoning are there?	Deductive, Inductive, Abductive, Common Sense.
What is Deductive reasoning?	Deductive reasoning is deducing new information from logically related known information.
What is Inductive reasoning?	Inductive reasoning is a form of reasoning to arrive at a conclusion using limited sets of facts by the process of generalization.
What is Abductive reasoning?	Abductive reasoning is a form of logical reasoning which starts with single or multiple observations then seeks to find the most likely explanation or conclusion for the observation.
What is Common Sense?	Common sense reasoning is an informal form of reasoning, which can be gained through experiences.
How Intelligence applications should behave?	Intelligence applications are expected to respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgement and intention.
What three ways of thinking do we need to learn in artificial intelligence?	Introspection, Psychological experiments, brain imaging.
What is Itrospection?	Trying to catch our own thoughts as they go by.
What is psychological experiments?	Observing a person in action.
What is brain imaging?	Observing the brain in action.
What is rational behavior?	Doing the right thing!
What is the right thing?	It is expected to maximize goal achievement, given the available information.
What are the advantages of studying AI as rational agent?	It is more general than using logic only, allows extension of the approach with more scientific methodologies.
What are the main roles that AI plays?	Study the intelligent part concerned with humans. Represent those actions using computers.
What is True AI?	True A.I. can improve on past iterations, getting smarter and more aware, allowing it to enhance its capabilities and its knowledge.
What do the currently popular approaches have?	Currently popular approaches include statistical methods, computational intelligence and traditional symbolic play parts designing and developing artificial intelligence.
What is the relationship among AI, ML, DL.	ML is a subset of AI. DL is a subset of ML.
What are the advantages of AI?	Reduces in human error, help in lessening repetitive work, provides Digital assistance, faster and more accurate decisions.
What are the disadvantages of AI?	Cost overruns, dearth of talent, lack of practical products, potential for misuse.
What is knowledge?	Knowledge is a collection of information about a domain that can be used to solve problems within a domain.
What are the organization of konwledge?	Wisdom, knowledge, information, data.
What is declarative knowledge?	Declarative knowledge is to know about something. It includes concepts, facts, and objects.
What is procedural Knowledge?	Procedural knowledge is a type of knowledge which is responsible for knowing how to do something.
What is heuristic konwledge?	Heuristic knowledge is rules of thumb based on previous experiences, awareness of approaches, and which are good to work but not guaranteed.
What is structural knowledge?	It describes relationships between various concepts and the relationship that exists between concepts or objects.
What is Meta-knowledge?	It is not specific to any single domain but aims to describe the structure of the data present in the knowledge systems.
What is logical representation?	Logical representation is a language that is free from ambiguity issue.
What categories can logical representation be divided into?	Propositional and predicate.
What is proposition?	It is a sentence that is either true or false.
What is semantic network?	A semantic network or net -graph structure is used to represent knowledge in patterns of interconnected nodes and arcs.
What do the production rules consist of?	IF(condition) and THEN(action).
What are the advantages of production rule?	The production rules are expressed in natural language. The production rules are expressed in natural language.
What are the disadvantages of production rule?	Production rule system does not exhibit any learning capabilities, as it does not store the result of the problem for the future uses.During the execution of the program, many rules may be active hence rule-based production systems are inefficient.
What is Knowledge-based System?	A knowledge-based system (KBS) is a form of artificial intelligence (AI) that aims to capture the knowledge of human experts to support decision-making.
What is medical expert system?	An expert system is a computer program that represents and reasons with knowledge of some specialist subject with a view to solving problems or giving advice.
What do the typical tasks for expert system have?	The interpretation of data, diagonosis of malfunctionsc, stuctural analysis, planning sequences of actions and predicting the future.
What do the complex decisions invovle?	Complex decisions involve intricate combination of factual and heuristic knowledge.
What do the structure of expert system reflect?	The structure of expert systems reflect the knowledge engineers understanding of the methods of representing knowledge and of how to perform intelligent decision making tasks with the support of a computer based system.
What is backward chaining?	Backward chaining starts from the goal and works backward through inference rules to find the required facts that support the goal.
What is the research strategy of backward chaining reasoning?	Backward chaining reasoning applies a depth-first search strategy.
What does the backward chaining apply to?	It is suitable for diagnostic, prescription, and debugging application.
What is forward chaining?	Forward chaining starts from known facts and applies inference rule to extract more data unit it reaches to the goal.
What is the research strategy of forward chaining reasoning?	Forward chaining reasoning applies a breadth-first search strategy.
What does the forward chaining apply to?	It is suitable for the planning, monitoring, control, and interpretation application.
What is knowledge engineering?	The process of building an expert system is called knowledge engineering and is done by a knowledge engineer.
What is knowledge engineer?	The knowledge engineer is a human with a background in computer science and AI and he knows how to build expert systems.
What is knowledge engineering?	Knowledge engineering is the acquisition of knowledge from a human expert or any other source.
What is Five-in-row system?	Five-in-row system is normally is implemented as a board game.
What is search?	Search is a about exploring alternatives.
What are the application of search?	Route finding, Package, Pipe routing, Comparison and classification of protein folds, Pharmaceutical drug design, Design of protein-like molecules.
What is category?	Incremental formulation, complete-State formulation, toy problem, real-world problem.
What is incremental formulation?	This problem involves operators that augment the state description, starting with an empty state.
What is complete-state formulation?	States are independent for each other.
What is toy problrm?	A toy problem is intended to illustrate or exercise various problem-solving methods.
What is real-word problem?	A real-world problem is one whose solutions people actually care about.
What’re the conditions for searching?	Observable, discrete, known, deterministic.
What is observable?	You always know what’s going on currently.
What is discrete?	Given any state, there are only finitely many actions to choose from.
What is known?	The agent knows which states are reached by performing the corresponding action.
What is deterministic?	Each action has exactly one outcome.
What are goodness of a search strategy?	Completeness, time complexity, space complexcity, optimality of the solution.
How to formulate searching?	States, initial state, actions, transition model, goal test, path cost.
What is states?	The basic unit for searching.
What is initial state?	The state that the agent starts in.
What is action?	The operations that you can perform for the current state.
What is transition model?	The outcome of actions.
What is goal test?	Which determines whether a state is a goal state.
What is path cost?	Assign a numeric cost to each path.
How to solve searching problems?	A solution is an action sequence, so search algorithms work by considering various possible action sequences.
What dose a graph consist of?	Nodes and arcs.
What dose the problem space consist of?	A state space, a set of operator.
What’s uninformed Searching?	While searching you have no clue whether one non-goal state is better than any other.
What is breadth-first search?	Expand shallowest unexpanded node.
What is fringe?	Nodes waiting in a queue to be explored, also called OPEN.
Does breadth-first search always find a solution if one exists?	Yes.
Does breadth-first search always find the best (least-cost) solution?	Yes, when all steps cost equally.
How long breadth-first search will take?	1+b+b^2+b^3+… +b^d (nodes until the solution)
What is depth-first search?	Expand deepest unexpanded node.
Does depth-first search always find a solution if one exists?	No: fails in infinite-depth spaces.
How long depth-first search will take?	O(b^m) with m=maximum depth
Does depth-first search always find the best (least-cost) solution?	No (It may find a non-optimal goal first).
What is iterative deepening search?	Run multiple DFS searches with increasing depth-limits.
Does iterative deepening  search always find a solution if one exists?	Yes.
Does iterative deepening search always find the best (least-cost) solution?	Only if path cost is a non-decreasing function of depth.
How long iterative deepening search will take?	b + (b+b^2) + .......(b+....b^d)  = O(b^d).
What is uniform-cost search?	Always expand the node on the fringe with minimum cost g(n).
Does uniform-cost search always find a solution if one exists?	Yes.
Does uniform-cost search always find the best (least-cost) solution?	Yes, for any step cost ≥ .
How long uniform-cost search will take?	of nodes with path cost ≤ cost of optimal solution.
How much space does uniform-cost search take to complete the run?	of nodes with path cost ≤ cost of optimal solution.
How much space does iterative deepening search take to complete the run?	O(bd)
How much space does depth-first search take to complete the run?	O(bm)
How much space does breadth-first search take to complete the run?	O(b^d) (keeps every node in memory, either in frontier or on a path to frontier).